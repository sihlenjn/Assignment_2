---
title: "Data Science for Industry Assignment 2"
author: "Sihle Njonga"
institute: "University of Cape Town"
toc: true
number-sections: false
format:
  html: 
    code-fold: false
    html-math-method: katex
fig-width: 8
fig-height: 5
fig-align: "center"
fig-asp: 0.8
fig-dpi: 300
bibliography: ref.bib
---

```{r setup,include = FALSE}
knitr::opts_chunk$set(echo = FALSE,warning = FALSE,message = FALSE)
```

```{r packages}
# Load all required packages
library(topicmodels)
library(tidyverse)
library(tidytext)
library(textdata) 
library(stringr)
library(gridExtra)
library(lubridate)
library(reshape)
library(reshape2)
library(kableExtra)

```

Abstract
In this paper, we explore the integration of Latent Dirichlet Allocation (LDA) , a powerful topic modeling technique, and sentiment analysis to uncover deeper insights from textual data. Textual data analysis has gained significant importance in various domains, such as social media, customer reviews, and Large Language Model. While LDA is widely used for topic extraction, and sentiment analysis is employed to determine the emotional tone of texts, combining these two techniques can yield a more comprehensive understanding of text data.
The objective of this paper was to conduct descriptive analysis using these methods. Our descriptive analysis of the presidents' SONA speeches using LDA topic modeling and sentiment analysis find some minor differences in the tone of the words and sentence used by the presidents. However, LDA managed to pick up that speeches occurring the during the Covid-19 years were about Covid-19.

# Introduction

Understanding the content and emotions hidden in volumes of text data is a great tool to get insights on the emotions of the meaning behind written text. In this paper, we look at the State of the Nation Address of the President of South Africa (SONA) speeches where the president of South Africa reports on the status of the country. These speeches are provided as full text sources from <https://www.gov.za/state-nation-address>. We look to conduct a descriptive analysis of the content of the speeches using sentiment analysis and topic modelling. This will look at the tone expressed in the speeches by the presidents through sentiment analysis. We also explore the underlying themes and patterns embedded in these speeches, this will be done via topic modelling. Using sentiment analysis, we will look at identifying trends over time in the speeches i.e. how have their sentiment changed over the years from 1994 to 2023 when analyzing the entire data set.

The structure of the paper is divided into the following sections:

-   *Data pre-processing*: This is explains how the data was cleaned and transformed to a compatible form such that we can conduct our analysis.

-   *Methodology*: We touch on the theory of sentiment analysis and steps taken to conduct Latent Dirichlet allocation (LDA) which is used for topic modelling.

-   *Results and discussion, conclusion* : This compromises of plots, tables and discussion on the results obtained.

# Methodology

## Data pre-processing

The data set used for this paper is sourced from <https://www.gov.za/state-nation-address>, the full speeches of State of the Nation Address from current and former presidents. The speeches included are from 1994 to 2023. All the analysis in this paper is conducted in R @R.

```{r}
load('data.RData')
```

The full speeches are read from Ian Durbach's Github repository. The resulting data frame has two columns *filename* and *speech*. New columns, president, year and date are added to indicate from which president the speeches are from and also the dates the speeches took place. The dates are generated from the first part of each speech since they all begin with a date. hese dates are then removed from all the speeches and any unnecessary text which will not be useful in our analysis. Such text include is removed includes website links , encoding for new lines **\\n** , backlashes . The generated are converted to same format given by $\text{dd-mm-yyyy}$. A new column, named `pres_num` , a factor variable used to denote each president with classes from 1 to 6.

## Sentiment Analysis

Sentiment analysis is the analysis of emotions, opinions and feelings of people expressed in written text. These can be in the form of speeches of presidents, tweets , events etc. Through sentiment analysis, one is able to gain deeper insights into body of text. In this section, we explore sentiment analysis conducted on the data set of the South African presidents' speeches from 1994 to 2023 and we also look at how these change over time.

We will be using the *bing* sentiment lexicons which comes with the **tidytext** package. This is a list of words labelled as positive or negative. We will analyse the sentiment of the words used by the presidents in their speeches and assess if these are positive or negative. It is for this reason that the token used to tokenize the data set is words. For cases where a word does not exist in the *bing* lexicon, these words will be labelled as neutral. The individual president's speeches will be analyzed. To analyse trends of the sentiments over time, the time period that will be considered is years. This will be done the entire data set and then consider individual presidents. The presidents that will be considered are Jacob Zuma and Thabo Mbeki.

The second part of this section, we look to assess the sentiment of longer sequences , sentences will considered. To conduct this analysis, we first tokenize the data set into sentences and then add an index column to the tokenized data for each sentence. The data is further tokenized into words for which their sentiments will be analysed. To analyse the sentiment of a sentence. This is done by analysing the sentiment of the individual words in the sentences and add up the sentiments over words. The net sentiment of the sentence will be given by the difference between the sum of positive sentiments and negative sentiments of the words in the sentence. Therefore, this implies that a negative net sentiment refers to a sentence that has a negative sentiment and vice versa. Similarly to part one of this section, we also look at the trends of the sentiment of the sentences over the years.  

## Topic modelling

Topic modelling is a natural language processing (NLP) technique used to summarize a document by describing it in terms of small number of topics. It is useful for task such as document clustering, content recommendation. In this paper, we will implement latent Dirichlet allocation (LDA), which is a popular method for doing topic modelling. Other methods such Latent Semantic analysis (LSA) , Probabilistic Latent Semantic analysis (pSLA) exists, the focus of this paper will be the LDA model for doing topic modelling. In LDA, each document is a mixture of topics and each topic is a mixture of words. To implement LDA, the following steps will be followed:

-   Add an extra column for speech id before the data is tokenized.

-   *Tokenization*: Tokenize the speech data set into individuals words and remove stop words.

-   *Document-term matrix*: Create a long tidy format document-term matrix where we count frequency of the words in each speech. i.e. the number of times each word is used in each speech. The document-term will not be created from stretch. The reason for this, the **topicmodels** package used to implement LDA requires the document-term matrix to be provided as a DocumentTermMatrix object. The document in our case are the individual speeches from each president.

-   *LDA modelling*: We fit the LDA model by first specifying the number of variables we wish to use

-   Topic and document inference: Infer on the topics for each document. This is to find topics contained in the documents, the gamma parameter will be used for this. It give the topic mixtures for each document. We also examine the most common words associated with each topic to interpret their meaning and compare different topics in terms of their difference.

The number of topics must be specified before training model. Given that all the speeches are about the State of the Nation Address , it's unlikely that the model will find different topics. Hence, the value of k used will be 3.

# Results and discussion

## Sentiment analysis

**Positive and negative words used in the speeches**

The data is tokenize to individual words and stop words are removed. We look at the most used positive and negative in all the speeches.

```{r allspeeches}
#| label: fig-Words
#| fig-cap: "Top 15 mostly common used positive and negative words by all presidents."


# fix the data of the last speech for Ramaphosa
sona$date[36] = '9-02-2023'

# tokenize the data into words and select the presidents and remove stop words
tidy_sona = unnest_tokens(sona,word,speech,token = "words",to_lower = T) %>%
              filter(!word %in% stop_words$word) # remove stop words

# load the bing lexicons
load("dsfi-lexicons.Rdata")

# Most positive in the entire speeches #####
speech_senti =  tidy_sona %>% left_join(bing) %>%                              
                select(word, sentiment,year,date) %>% 
                mutate(sentiment = ifelse(is.na(sentiment),'neutral',sentiment)) 
              # make all the word neutral not in the lexicon neutral

pos = speech_senti %>% filter(sentiment == 'positive') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 15) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill = 'green')+
        coord_flip()+xlab('') + ylab('n')+ggtitle("positive")+
        theme(axis.text.y = element_text(size = 10))

neg = speech_senti %>% filter(sentiment == 'negative') %>% count(word) %>%
          arrange(desc(n)) %>% filter(rank(desc(n)) <= 15) %>%
          ggplot(aes(reorder(word,n),n))+geom_col(fill = 'red')+
          coord_flip()+xlab('') + ylab('n')+ggtitle("negative")+
          theme(axis.text.y = element_text(size = 10))
grid.arrange(pos,neg,ncol=2)

```

@fig-Words show the top 15 commonly used words by the president in their speeches, both negative and positive. The most commonly used positive words in the speeches are regard, improve and support. This is quite surprising, one would expect the words such freedom and empowerments to be in the top 3 given that a random person would generally expect these words from the president of a country.

Looking at negative words, crime and poverty top the list , with corruption ranked fourth. For a person invested in the state of South Africa especially politics, it will be no surprise that these words are ranked in the top in the lost of most used negative.

Having looked at all the speeches without grouping by presidents, of interest will be positive and negative words used by each president in their speeches.

```{r}
# Most pos and neg by presidents ####

pres_words = list()
for (i in 1:6) {
  pres_words[[i]] = tidy_sona  %>% filter(pres_num==i) %>% select(word,date,year)
}
names(pres_words) = unique(sona$president_13)

# load the bing lexicon
# load 

pres_sentiment <- list()
for (i in 1:6) {
  pres_sentiment[[i]] = pres_words[[i]] %>% left_join(bing) %>%                              
                        select(word, sentiment, everything()) %>% 
                        mutate(sentiment = ifelse(is.na(sentiment),'neutral',sentiment)) 
    # make all the word neutral not in the lexicon neutral
}
names(pres_sentiment) = unique(sona$president_13)
```

```{r}
#| label: fig-indiviPresident
#| fig-cap: "Top 5 mostly common used positive words by each president."
# Look top 5  positive for each president
n1 =pres_sentiment[[1]] %>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill = 1)+
  coord_flip()+xlab('') + ylab('n')+ggtitle('Mandela')+
  theme(axis.text.y = element_text(size = 10))
n2 = pres_sentiment[[2]] %>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill =2)+
  coord_flip()+xlab('') + ylab('n')+ggtitle('deKlerk')+
  theme(axis.text.y = element_text(size = 10))
n3 = pres_sentiment[[3]]%>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill = 3)+
  coord_flip()+xlab('') + ylab('n')+ggtitle('Mbeki')+
  theme(axis.text.y = element_text(size = 10))
n4 = pres_sentiment[[4]] %>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill = 4)+
  coord_flip()+xlab('') + ylab('n')+ggtitle('Zuma')+
  theme(axis.text.y = element_text(size = 10))
n5 = pres_sentiment[[5]]  %>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill =5)+
  coord_flip()+xlab('') + ylab('n')+ggtitle('Motlanthe')+
  theme(axis.text.y = element_text(size = 10))

n6 = pres_sentiment[[6]]  %>% filter(sentiment == 'positive') %>% count(word) %>%
  arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
  ggplot(aes(reorder(word,n),n))+geom_col(fill =6 )+
  coord_flip()+xlab('') + ylab('n')+ggtitle('Ramaphosa')+
  theme(axis.text.y = element_text(size = 10))
grid.arrange(n1,n2,n3,n4,n5,n6,ncol=2,nrow=3)

```

In @fig-indiviPresident , we can see that the word regard appears in to be most used positive word by the president. With 3 of the president using this words, Mandela , Mbeki and Motlanthe. This is expected as this was the most used word when look at all the speeches. The most popular word across all the presidents is freedom with the exception of Ramaphosa. We also note that deKlerk's counts are very low compared to the other presidents. The reason for this is that deKlerk only made one speech which was shorter in terms of the number of sentence compared to the other 5 presidents. Motlanthe also made one speech , but in terms length, it was in the range of other presidents who had longer speeches. If we were summarize the theme of all these words,based on these plots, it's freedom, improvement and progress.

```{r negativewords}
#| label: fig-indiviPre
#| fig-cap: "Top 5 mostly common used negative words by each president."
# Look top 5  negative for each president
p1 = pres_sentiment[[1]] %>% filter(sentiment == 'negative') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill = 1)+
        coord_flip()+xlab('') + ylab('n')+ggtitle('Mandela')+
        theme(axis.text.y = element_text(size = 10))
p2 = pres_sentiment[[2]] %>% filter(sentiment == 'negative') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill =2)+
        coord_flip()+xlab('') + ylab('n')+ggtitle('deKlerk')+
        theme(axis.text.y = element_text(size = 10))
p3 = pres_sentiment[[3]]%>% filter(sentiment == 'negative') %>% count(word) %>%
      arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
      ggplot(aes(reorder(word,n),n))+geom_col(fill = 3)+
      coord_flip()+xlab('') + ylab('n')+ggtitle('Mbeki')+
      theme(axis.text.y = element_text(size = 10))
p4 = pres_sentiment[[4]] %>% filter(sentiment == 'negative') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill = 4)+
        coord_flip()+xlab('') + ylab('n')+ggtitle('Zuma')+
        theme(axis.text.y = element_text(size = 10))
p5 = pres_sentiment[[5]]  %>% filter(sentiment == 'negative') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill =5)+
        coord_flip()+xlab('') + ylab('n')+ggtitle('Motlanthe')+
        theme(axis.text.y = element_text(size = 10))
p6 = pres_sentiment[[6]]  %>% filter(sentiment == 'negative') %>% count(word) %>%
        arrange(desc(n)) %>% filter(rank(desc(n)) <= 5) %>%
        ggplot(aes(reorder(word,n),n))+geom_col(fill =6 )+
        coord_flip()+xlab('') + ylab('n')+ggtitle('Ramaphosa')+
        theme(axis.text.y = element_text(size = 10))
grid.arrange(p1,p2,p3,p4,p5,p6,ncol = 2,nrow = 3)

```

@fig-indiviPre displays the top 5 most used negative words by the presidents. Crime, Issues and Poverty dominates. An interesting observation, is that none of these words are popular in deKlerk's speech. This is where things can be misleading and we have to be very careful at how we view these results. This certainly does not mean crime and poverty were not present during those times and also does not mean they were. if this graphic were to be given to someones with no context, a lot of misinterpretation would occur. Our interest is looking at the positive and negative words used by the presidents in their speeches and how these vary from one president to another

**Sentiment over time**

This part look at how the sentiment of the words in these speeches change over time. This is done based on year, which is from 1994 to 2023 by determining the frequency of positive and negative words. The overall sentiment over the years is indicated in @fig-time . Based on this plot, the proportion of positive sentiment is exceeds the proportion of negative sentiment given that the plot indicating the positive sentiment is always above the the one showing negative sentiment. The smooth lines can be thought of showing the predicted distribution in the long-run. Around 2014 , we notice a drop in both sentiments and starts to gradual pick-up again.

```{r overtime,message=FALSE,warning=FALSE}
#| label: fig-time
#| fig-cap: "Sentiment of the words used in the speeches from 1994 to 2023"

#  Changes in sentiment over time  ####

# Remove neutral words as they are dominant
# all speeches
senti_per_year <- speech_senti %>% group_by(year, sentiment) %>%
                        summarize(n = n())

# ggplot(filter(senti_per_year , sentiment != 'neutral'),aes(x=year,y=n,fill=sentiment)) +
#   geom_col() + theme_minimal() +
#   theme(axis.text.x = element_text(angle = 90, hjust = 1,size=10))

# plot the proportion
senti.prop <-senti_per_year  %>% left_join(senti_per_year  %>% 
                          group_by(year) %>% 
                          summarise(total = sum(n))) %>%
                          mutate(freq = n/total) 


# sentiment over all speeches
senti.prop %>% filter(sentiment != 'neutral') %>%
                ggplot(aes(x = year, y = freq, colour = sentiment,group=sentiment)) +
                geom_line() + geom_smooth(aes(colour = sentiment))+
                xlab('year') + ylab('frequency')+
                theme(axis.text.x = element_text(angle = 90, hjust = 1,size=10),
                      axis.text.y = element_text(size = 10))

```

For the individual presidents, we will look at Jacob Zuma and Thabo Mbeki. The proportion of positive and negative sentiments in their speeches is shown in @fig-zuma . For Mbeki, we can see that the proportion of words with positive sentiment exceeds the of words with negative sentiments. On the other hand, we notice that in Zuma's case, the curves are quite close to each other with a decreasing curve for the proportion of words with positive sentiment and increasing curve for the proportion of words with negative sentiment starting around 2015. However, this is a small size as a president can only serve for a certain period of time.

```{r }
#| label: fig-zuma
#| fig-cap: "Sentiment of the Zuma and Mbeki's words used in their speeches from 1994 to 2023"

# Look at Zuma and Mbeki
# individual presidents
year_sentiments = list()
for (i in 1:6) {
  year_sentiments[[i]] <- pres_sentiment[[i]] %>% group_by(year, sentiment) %>%
                              summarize(n = n())
}

# Proportion of sentiments for each president
prop_year = list()
for (i in 1:6) {
  prop_year[[i]] <-year_sentiments[[i]] %>% left_join(year_sentiments[[i]]%>% 
                                              group_by(year) %>% 
                                              summarise(total = sum(n))) %>%
                                              mutate(freq = n/total) 
}
# Mbeki
pp1 = prop_year[[3]] %>% filter(sentiment != 'neutral') %>%
          ggplot(aes(x = year, y = freq, colour = sentiment,group=sentiment)) +
          geom_line() + geom_smooth(aes(colour = sentiment))+
          xlab('year') + ylab('freq')+ggtitle('Mbeki')
          theme(axis.text.x = element_text(angle = 90, hjust = 1,size=10),
                axis.text.y = element_text(size = 10))
# Zuma
pp2 =prop_year[[4]] %>% filter(sentiment != 'neutral') %>%
        ggplot(aes(x = year, y = freq, colour = sentiment,group=sentiment)) +
        geom_line() + geom_smooth(aes(colour = sentiment))+
        xlab('year') + ylab('freq')+ggtitle('Zuma')+
        theme(axis.text.x = element_text(angle = 90, hjust = 1,size=10),
              axis.text.y = element_text(size = 10))

grid.arrange(pp1,pp2,ncol=2)
```

**Aggregating sentiment over words**

In the previous analysis, we only looked at individual words. We use sentence in this case, so the starting point is to tokenize the data by sentences. After tokenizing, we add an index for each of the resulting sentences. To determine the sentiment of a sentence, net sentiment , it is difference between sum positive words and negative words. A negative net sentiment indicated a negative sentence and positive one indicate a positive sentence with 0 indicating neutral. @fig-sentence shows the proportion of negative and positive sentiments for sentence over the years.

```{r}
sona_sentence  = unnest_tokens(sona,sentence,speech,token = "sentences")
sona_sentence = sona_sentence %>% mutate(index = c(1:nrow(sona_sentence)))

# Tokenize the sona sentence
tidy_words = unnest_tokens(sona_sentence,word,sentence,token = "words") %>%
          filter(!word %in% stop_words$word, str_detect(word, '[A-Za-z]')) # remove stop words
tidy_words = tidy_words %>% select(index,year, pres_num, index,word)

# sentiments per sentence
senti_word =  tidy_words %>% left_join(bing) %>%                              
              select(index,word, sentiment,year) %>% 
              mutate(sentiment = ifelse(is.na(sentiment),'neutral',sentiment)) 

sentiments_per_sentence <- senti_word %>% group_by(index) %>%
                           summarize(net_sentiment = (sum(sentiment == 'positive') - sum(sentiment == 'negative')),year =  year)

# convert year to character so that it matches the sona-year
sentiments_per_sentence$year = as.character(sentiments_per_sentence$year)

# # 2020 top negative  and positive sentences
# sona_sentence %>% left_join(sentiments_per_sentence) %>% 
#               arrange(desc(net_sentiment)) %>%
#        select(sentence, net_sentiment,index) 

neg_senti = sentiments_per_sentence %>%
  group_by(year) %>%
  summarize(prop_neg=sum(net_sentiment < 0)/n()) 

pos_senti = sentiments_per_sentence %>%
  group_by(year) %>%
  summarize(prop_pos=sum(net_sentiment > 0)/n()) 
```

```{r }
#| label: fig-sentence
#| fig-cap: "Proportion of positive and negative sentence in the president' speeches from 1994 to 2023."
s1 = ggplot(neg_senti,aes(x=as.numeric(year), y=prop_neg))+
    geom_line(col='red',lwd=1)+geom_smooth()+xlab('year') + ylab('proportion of negative sentiments')+
    theme(axis.text.x = element_text(size=10),
          axis.text.y = element_text(size = 10))


s2 = ggplot(pos_senti,aes(x=as.numeric(year), y=prop_pos))+
  geom_line(col='green',lwd=1)+geom_smooth(col="purple")+xlab('year') + ylab('proportion of positive sentiments')+
  theme(axis.text.x = element_text(size=10),
        axis.text.y = element_text(size = 10))

grid.arrange(s1,s2)
```

The red line indicate negative sentiment and the green one indicates positive sentiment. The proportion of sentence with positive sentiments was at its peak between 2005 and 2009 afterwards a decrease can be seen. Thabo Mbeki was the president during this period and after this period , Zuma and Motlanthe took over. Although Montlanthe only served for a year.

With respect to sentences with negative sentiment, the top graph (red) shows a gradual decrease which means the sentences used by the president were positive. In 2015, we start noticing an increase. Comparing the two, the proportion of positive sentiments fluctuates compared to the negative sentiments.

## Topic modelling

To fit LDA we follow the step outlined in the methodology section.

Nothing really interesting as these speeches are drafted way before time hence one is likely to see less negative words.

```{r}
sona_topic = sona %>% select(speech,pres_num)
sona_topic$pres_num = factor(sona_topic$pres_num)
sona_topic = sona_topic %>% mutate(speech_id = 1:nrow(sona_topic))

# tokenize the data by words and remove stop worts
topic_tidy <- sona_topic %>% 
  unnest_tokens(word,speech, token = 'words', to_lower = T) %>%
  filter(!word %in% stop_words$word)

# remove numbers
d1 = topic_tidy  %>%  arrange(word)
topic_tidy = d1[-c(1:2407),] 

# count number of times each word appears
  topic_tdf <- topic_tidy %>%
  group_by(speech_id,word) %>%
  count() %>%  
  ungroup()

dtm_speeches <-  topic_tdf%>%cast_dtm(speech_id, word, n)

speeches_lda <- LDA(dtm_speeches, k = 3, control = list(seed = 1234))
```

**Word-topic probabilities**

```{r}
term <- as.character(speeches_lda @terms)
topics = list()
for (i in 1:3) {
  topics[[i]] = speeches_lda @beta[i,]
}

# convert to probabilities
speeches_topics <- tidy(speeches_lda, matrix = 'beta')

```

To draw out differences between the 3 topics, we look at words that have the greatest difference in beta values between the 3 topics. This is done by taking the log ratio of the two betas of the topics to be compared , the ratio is given by $\log_2 (\beta_2/\beta_1)$ We compare all 3 topics in turns, i.e. 1 vs 2 , 1 vs 3 and 3 vs 2 .

```{r 1vs2}
#| label: fig-t12
#| fig-cap: "Words with greatest difference in $\beta$ between topic 1 and topic 2"

# beta spread
beta_spread <- speeches_topics %>%
  mutate(topic = paste0('topic', topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>%
  filter(topic1 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic1 / topic2))

beta_spread%>%
            group_by(direction = log_ratio > 0) %>%
            top_n(10, abs(log_ratio)) %>%
            ungroup() %>%
            mutate(term = reorder(term, log_ratio)) %>%
            ggplot(aes(term, log_ratio)) +
            geom_col() +
            labs(y = 'Log2 ratio of beta in topic 1 / topic 2') +
            coord_flip()
```

The word that is common is topic 1 is "madame" but this word is used in every speech so this implies the speeches could all be the same topic. Topic 1 is characterized by the word "compatriots" Given that majority of the words have log ratio that relatively small, the topics are likely to be same topic.

```{r 3vs2}
#| label: fig-t23
#| fig-cap: "Words with greatest difference in $\beta$ between topic 2 and topic 3"
# topic 3 vs topic 2
# beta spread
beta_spread <- speeches_topics %>%
  mutate(topic = paste0('topic', topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>%
  filter(topic3 > .001 | topic2 > .001) %>%
  mutate(log_ratio = log2(topic3 / topic2))

beta_spread %>%
          group_by(direction = log_ratio > 0) %>%
          top_n(10, abs(log_ratio)) %>%
          ungroup() %>%
          mutate(term = reorder(term, log_ratio)) %>%
          ggplot(aes(term, log_ratio)) +
          geom_col() +
          labs(y = 'Log2 ratio of beta in topic 3 / topic 2') +
          coord_flip()
```

The word that is common is topic 2 is "pandemic" and "covid" , this topic was definitely about Covid-19 and was made after the year 2020. All the words in Topic 3 are have a small log ratio meaning topic 2 and topic 3 are similar.

```{r 3vs1}
#| label: fig-13
#| fig-cap: "Words with greatest difference in $\beta$ between topic 1 and topic 3"
# topic 3 vs topic 1
# beta spread
beta_spread <- speeches_topics %>%
  mutate(topic = paste0('topic', topic)) %>%
  pivot_wider(names_from = topic, values_from = beta) %>%
  filter(topic3 > .001 | topic1 > .001) %>%
  mutate(log_ratio = log2(topic3/ topic1))

beta_spread %>%
            group_by(direction = log_ratio > 0) %>%
            top_n(10, abs(log_ratio)) %>%
            ungroup() %>%
            mutate(term = reorder(term, log_ratio)) %>%
            ggplot(aes(term, log_ratio)) +
            geom_col() +
            labs(y = 'Log2 ratio of beta in topic 3 / topic 1') +
            coord_flip()
```

Comparing Topic 1 and Topic 3: in Topic 1 is characterized by pandemic , covid and capture which further confirms that this topic was about Covid-19. For Topic 1, madame and context are more common. In all the three comparisons made in @fig-t12 , @fig-13 and @fig-t23 we notice all these topics are not different, this was expected as each document ( speech) come from the president speeches which are all about the government, politics and South Africa.

**Document-topic probabilities**

The document-topic probabilities help us to assess whether a particular document is mostly about Topic $i$. We deduced that Topic 3 and Topic 2 were about Covid 19 based on the plots from the word-topic probabilities. We expect all the speeches after 2020 which were done by Cyril Ramaphosa to be predicted to be about either Topic 3 or Topic 2.

```{r}
# Document-topic probabilities ####
spechees_gamma <- sona_topic %>% 
  left_join(tidy(speeches_lda, matrix = 'gamma') %>% 
              mutate(speech_id= as.numeric(document)) %>%       
              select(-document) %>%
              spread(key = topic, value = gamma, sep = '_'))


tb1 = spechees_gamma %>% filter(pres_num == 6) %>% arrange(topic_3) %>%
                              select(speech_id, topic_1, topic_2,topic_3)
kable(tb1, "pipe", digits = 4,caption = "Topics for all Ramaphosa's speeches")

```

Indeed, the model predicted these speeches are predicted to be about Topic 2 or 3 as the Table show probabilities of 0 under Topic 1.

We explore Zuma's speeches to see which topic the model predicted them to be. The table below shows that Zuma's speeches were about Topic 2

```{r}
tb2 = spechees_gamma %>% filter(pres_num == 4) %>% arrange(desc(topic_2)) %>%
                              select(speech_id, topic_1, topic_2,topic_3)
apply(tb2[,-1], 2, sum)
kable(tb2, "pipe", digits = 4,caption = "Topics for all Zuma's speeches")

```

# Conclusion

In this paper, we performed descriptive analysis using sentiment analysis and LDA on the speeches by the presidents of South Africa. The sentiment analysis was to gauge the emotional tone of the words and sentences used by the presidents in their speeches. There was no great difference in the tone of the words used. Taking into account that the speeches are probably written by people who are part of the presidency, who their job is edit and write these speeches. It was always going to be difficult problem to pinpoint the tone of the speeches to the president and also to have major differences in their speeches. If a president spends more than 5 years in office, it's likely that the president might have the same writer for all those years. This means there won't be any significant differences in the speeches of the president if we were to compare them from year to year. Of course, with the exception if there's a global event that affect the entire world then the speech might change.

The LDA model predicted some of the speeches that took place during the pandemic to be about Covid-19. We did not know the topics beforehand but the model did not find any major differences between different the topics used. With the exception of the Covid-19 one. This is due to the fact these are all government speeches so they could be about the same topic.

The lexicons provided by the R package are subject so instead of using one lexicon, *bing*. One could extend this by conducting descriptive analysis using the other lexicons and compare the results. Given that South Africa has so many languages and some non-English words were used in the speeches of the presidents. It would really interesting if there was a lexicon for non-English words, maybe one of the official languages here in South Africa.
